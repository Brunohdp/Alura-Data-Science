# -*- coding: utf-8 -*-
"""Corretor

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/13NQPcUsZ70fx-y7V5I5CJS7RDCZWSku0

# <font color = green>Aula 1 – Explorando Um Projeto De NLP

## <font color = blackpink>Importando Um Corpus Textual
"""

with open('artigos.txt', 'r') as f:
  artigos = f.read()

print(artigos[:500])

"""---

## <font color = blackpink>Tokenização
"""

len(artigos)

texto_exemplo = 'Olá, tudo bem?'
tokens = texto_exemplo.split()
print(tokens)

len(artigos.split())

"""---
---

# <font color = green>Aula 2 – Utilizando NLTK Para Tokenizar Um Texto

## <font color = blackpink>Refinando a Tokenização
"""

import nltk
nltk.download('punkt')

palavras_separadas = nltk.tokenize.word_tokenize(texto_exemplo)
palavras_separadas

"""---

## <font color = blackpink>Separando Palavras De Tokens
"""

'palavra'.isalpha()

def separa_palavras(lista_tokens: list):
  lista_palavras = []
  for token in lista_tokens:
    if token.isalpha():
      lista_palavras.append(token)
  return lista_palavras

separa_palavras(palavras_separadas)

"""---

## <font color=blackpink>Contando Palavras Do Corpus
"""

lista_tokens = nltk.tokenize.word_tokenize(artigos)
lista_palavras = separa_palavras(lista_tokens)
print(f'O número de palavras é: {len(lista_palavras)}')

"""---

## <font color = blackpink>Normalização
"""

print(lista_palavras[:5])

def normalizacao(lista_palavras: list):
  lista_normalizada = []
  for palavra in lista_palavras:
    lista_normalizada.append(palavra.lower())
  return lista_normalizada

lista_normalizada = normalizacao(lista_palavras)
lista_normalizada[:5]

"""---

## <font color=blackpink>Tipos De Palavras
"""

set([1,1,1,3,4,4,5,8,2,4,5,5,6,6])

lista_unica = set(lista_normalizada)
len(lista_unica)

